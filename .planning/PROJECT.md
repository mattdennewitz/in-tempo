# InTempo

## What This Is

A browser-based generative performance engine inspired by Terry Riley's "In C." Simulated performers independently navigate a shared score of short melodic patterns, following Riley's coordination rules — stay within a few patterns of each other, repeat freely, drop out and rejoin — producing an emergent, shifting tapestry of sound. Three composition modes (Riley's original, generative, Euclidean) with sampled and synthesized instruments. Built with the Web Audio API for rock-solid timing, React + shadcn + Vite for the interface.

## Core Value

The ensemble behavior must feel alive — performers making believable musical decisions (repetition, dropouts, unison-seeking, density-awareness) over a precisely timed audio engine, so each performance is unique and compelling to watch and listen to.

## Requirements

### Validated

- ✓ Precalculated score from Riley's 53 patterns as default mode — v1.0
- ✓ Algorithmically generated score mode (patterns in the style of In C) — v1.0
- ✓ Euclidean mode: patterns generated by Bjorklund's algorithm — v1.0
- ✓ Dynamic performer count — add/remove players before or during performance — v1.0
- ✓ Emergent performer AI: weighted decisions, band enforcement, dropout/rejoin, unison-seeking — v1.0
- ✓ Riley's rules enforced: sequential traversal, 2-3 pattern band, no skipping backward — v1.0
- ✓ Toggleable steady eighth-note pulse (high C) — v1.0
- ✓ User-configurable global BPM — v1.0
- ✓ Start, stop, and reset performance controls — v1.0
- ✓ User is a spectator — no interaction with individual performers during performance — v1.0
- ✓ Mix of synth and sampled instrument voices (piano, marimba), assigned per-player — v1.0
- ✓ Per-performer status: playing/silent, current pattern number, rep tracking — v1.0
- ✓ Canvas-based performer visualization — v1.0
- ✓ Natural fade ending: performers drop out one by one — v1.0
- ✓ Rock-solid Web Audio API timing (AudioContext lookahead scheduling) — v1.0
- ✓ Per-note velocity humanization with personality, metric accents, and phrase contour — v1.1
- ✓ Humanization UI toggle with subtle/moderate/expressive intensity — v1.1
- ✓ Default 4 performers — v1.1
- ✓ Multi-track MIDI export with per-performer tracks, GM instruments, tempo, and humanized velocities — v1.1

### Active

- [ ] Stereo spread — performers panned across the stereo field
- [ ] Pattern visualization — score overview + per-performer abstract geometry
- [ ] Shareable performances — seeded PRNG for exact note-by-note reproduction via URL
- [ ] Microtiming humanization — swing and rubato for more organic feel

### Out of Scope

- Real-time multiplayer (human performers over network) — too complex
- Mobile-optimized layout — desktop-first
- Recording/export to audio file (WAV/MP3) — MIDI export covers notation needs
- User conducting/intervention during performance — spectator only by design
- GT Canon font — deferred, Courier fallback works
- Semafor/FT color palette — deferred from v1.0

## Context

Terry Riley's "In C" (1964) is a seminal minimalist composition. 53 short melodic modules are played in sequence by any number of performers. The magic is in the simple rules: go in order, repeat freely, stay close to each other, listen and adjust. This produces emergent phasing, canonic textures, and dynamic waves without a conductor.

Shipped v1.1 with 4,360 LOC TypeScript/TSX across 6 phases (16 plans).
Tech stack: React 19, Vite, shadcn/ui, Tailwind CSS v4, Web Audio API (AudioWorklet), smplr for sampled instruments, midi-writer-js for MIDI export.

## Constraints

- **Tech stack**: React + shadcn/ui + Vite for UI; Web Audio API for all audio
- **Font**: GT Canon (user will provide the font files); Courier New as fallback
- **Timing**: All note scheduling must use AudioContext.currentTime lookahead, never setTimeout/setInterval for musical timing
- **Browser**: Modern Chromium-based browsers as primary target (best Web Audio support)

## Key Decisions

| Decision | Rationale | Outcome |
|----------|-----------|---------|
| Spectator-only interaction | Preserves the emergent, self-organizing nature of the piece | ✓ Good |
| Emergent AI over simple random | Weighted decisions with band enforcement produce believable musical behavior | ✓ Good |
| Precalculate score | Avoids runtime computation; enables visualization ahead of playback | ✓ Good |
| AudioWorklet for synthesis | Dedicated audio thread prevents main-thread jank from blocking audio | ✓ Good |
| Lookahead scheduler (Two Clocks) | Chris Wilson pattern: schedule ahead via currentTime for glitch-free timing | ✓ Good |
| Immutable frozen snapshots per tick | Prevents order-of-evaluation bugs across performer agents | ✓ Good |
| Voice pool with stealing | Oldest-voice stealing handles contention naturally; pool only grows, never shrinks | ✓ Good |
| Deterministic instrument assignment | performerId % 3 gives stable, varied timbres without randomness | ✓ Good |
| smplr for sampled instruments | CDN-loaded piano/marimba samples — no local audio files needed | ✓ Good |
| Bjorklund/Euclidean for rhythms | Mathematically even onset distribution produces world-music-style rhythms | ✓ Good |
| Multiplicative velocity model | Four layers (jitter, personality, accent, contour) multiply against base — floor at 0.3 prevents inaudible notes | ✓ Good |
| Pattern-relative accent | noteIndexInPattern===0 rather than global beat counter — works across all score modes | ✓ Good |
| velocityConfigRef pattern | Scheduler holds ref to config object — avoids constructor changes, hot-swappable | ✓ Good |
| midi-writer-js for MIDI export | Lightweight library, velocity 1-100 scale, startTick absolute positioning | ✓ Good |
| Passive MidiRecorder pattern | Recorder ref on Scheduler, same pattern as velocityConfigRef — no event system needed | ✓ Good |
| Ghost note trimming | Filter events by beatIndex < stopBeat — eliminates lookahead artifacts in MIDI | ✓ Good |

## Current Milestone: v1.2 Polish

**Goal:** Elevate the listening and sharing experience with stereo spread, pattern visualization, shareable seeded performances, and microtiming humanization.

**Target features:**
- Stereo spread — pan performers across the stereo field
- Pattern visualization — score-wide overview + per-performer abstract geometry
- Shareable performances — seeded PRNG for exact reproduction via URL
- Microtiming — swing/rubato humanization complementing velocity

## Shipped Milestones

- **v1.0 MVP** — Audio engine, ensemble AI, visualization, 3 composition modes (shipped 2026-02-15)
- **v1.1 MIDI** — Velocity humanization, MIDI export, default 4 performers (shipped 2026-02-15)

---
*Last updated: 2026-02-15 after v1.2 milestone start*
